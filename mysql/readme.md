<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again -->

* [分表](#分表)
  * [1 为什么要分表](#1-为什么要分表)
  * [2 分表的常用方法](#2-分表的常用方法)
  * [3 垂直拆分](#3-垂直拆分)
  * [4 水平拆分](#4-水平拆分)
  * [5 水平分表后的分页排序问题](#5-水平分表后的分页排序问题)
* [分区](#分区)
  * [1 为什么要分区](#1-为什么要分区)
  * [2 如何分区](#2-如何分区)
  * [3 分区的缺点](#3-分区的缺点)
* [分库](#分库)
  * [1 为什么要分库](#1-为什么要分库)
  * [2 分库常见问题](#2-分库常见问题)
  * [3 阿里云drds介绍](#3-阿里云drds介绍)
* [索引](#索引)
  * [1 联合索引](#1-联合索引)
  * [2 聚簇索引](#2-聚簇索引)
  * [3 覆盖索引](#3-覆盖索引)
  * [4 索引下推](#4-索引下推)
* [事务和锁](#事务和锁)
  * [1 事务的特点](#1-事务的特点)
  * [2 隔离级别](#2-隔离级别)
  * [3 锁](#3-锁)
  * [4 mvcc](#4-mvcc)
* [主从](#主从)
  * [1 主从的好处](#1-主从的好处)
  * [2 主从原理](#2-主从原理)
  * [3 主从数据不一致](#3-主从数据不一致)
  * [4 主从同步延时问题](#4-主从同步延时问题)

<!-- markdown-toc end -->

# 分表

## 1 为什么要分表
单表数据量太大之后,极大的影响sql性能,为了减小数据库的负担，缩短查询时间,一般数据量上了1000万之后很有必要分表(在数据量越来越大之后,首先是以聚簇索引建立的b+树,变得很大,执行一次sql无论是查询还是插入操作的tree节点和以前数据量小的时候都不是一个难度级别)

## 2 分表的常用方法
一般分为垂直拆分 和 水平拆分

## 3 垂直拆分
为了解决一张表字段太多(比如100以上),查找几百条数据就跨页的问题(InnoDB存储引擎也有自己的最小储存单元——页（Page）,一个页的大小是16K.),可以把不常用字段或单个字段存储很多数据的列拆分出去

## 4 水平拆分
大致的一些方法:
+ 按照一些明显标示来划分,比如区域,时间等
+ 对id取模计算分表
+ 用一张中间表做映射

## 5 水平分表后的分页排序问题
+ 如果是刚才符合特定的业务场景,列如按照时间分表,时间排序就很简单,几乎不用任何处理
+ 使用搜索引擎数据库比如 solr sphinx es等,搜索符合范围的 找到主键id和所在表,再去表里面查一次
+ 使用mysql本身的merge引擎实现水平分表,但是merge只支持myisam引擎

# 分区

## 1 为什么要分区
+ 分区可以在一个表中存储比单个磁盘或文件系统分区上的数据更多的数据,因为我们可以将分区表存储在不同物理磁盘上
+ 对已过期或者不需要保存的数据,可以通过删除与这些数据有关的分区来快速删除数据,他的效率远比delete高
+ 优化查询,在where子句中包含分区条件时,可以只扫描必要的一个或者多个分区来提高查询效率 列如:
```
SELECT * FROM t PARTITION（p0，p1）WHERE c <5
```
仅选择与WHERE条件匹配的分区p0和p1中的那些行.在这种情况下,MySQL不检查表t的任何其他分区
+ 涉及聚合函数SUM(),COUNT()的查询时,可以容易的在每个分区上并行处理,例如在执行下面这条语句:
```
SELECT salesperson_id，COUNT（orders）as order_total FROM sales GROUP BY salesperson_id
```
会在每个分区上都同时运行查询
+ 凭借在多个磁盘上传播数据，实现更高的查询吞吐量

## 2 如何分区
+ RANGE分区:基于一个给定连续区间范围,把数据分配到不同的分区
+ LIST分区:类似RANGE分区,区别在LIST分区是基于枚举出的值列表分区,RANGE是基于给定连续区间范围分区
+ HASH分区:基于用户定义的表达式返回值来选择分区,该表达式对要插入到表的行中列值操作
+ KEY分区:类似HASH，但是HASH允许使用用户自定义表达式,而KEY分区不允许,它需要使用MySQL服务器提供的HASH函数,同时HASH分区只支持整数分区,而KEY分区支持除BLOB和TEXT类型外其他列

但是无论是哪一种分区类型,要么分区表上没有主键/唯一键,要么分区表的主键/唯一键都必须包含分区键,否则会报错

## 3 分区的缺点
分区表有这么多好处,那为什么平时使用的频率并不高呢,我们更乐意使用分表分库要解决数据量和并发的问题,分区在实际使用中大致有以下缺点:
+ 分区表,分区键设计不太灵活,如果不走分区键,很容易出现全表锁
+ 一旦数据量并发量上来,如果在分区表实施关联,就是一个灾难
+ 自己分库分表，自己掌控业务场景与访问模式,可控,分区表,研发写了一个sql,都不确定mysql是怎么玩的,不太可控

# 分库

## 1 为什么要分库
当单台mysql的qps达到一千以上,数据库的数据处理能力成为瓶颈,就要开始考虑分库的问题

## 2 分库常见问题
### 跨库join
在拆分之前，系统中很多列表和详情页所需的数据是可以通过sql join来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，join将变得非常麻烦。而且基于架构规范，性能，安全性等方面考虑，一般是禁止跨库join的,以下是一些常用的解决方法
+ 全局表,系统中所有模块都会依赖的一些表,在需要跨库的数据在全局表中保存,这类数据一般很少修改,不用考虑一致性的问题
+ 字段冗余,就可以不用做关联,是一种典型用空间换时间体现
+ 数据同步
+ 系统层组装,在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装

### 跨库事务,也就是分布式事务
+ 2pac
+ tcc
+ 本地消息表
+ mq事务
+ saga事务
[参考链接](https://juejin.im/post/5b5a0bf9f265da0f6523913b)

## 3 阿里云drds介绍
分布式关系型数据库服务（Distributed Relational Database Service，简称 DRDS）是阿里巴巴致力于解决单机数据库服务瓶颈问题而自主研发推出的分布式数据库产品。DRDS 高度兼容 MySQL 协议和语法，支持自动化水平拆分、在线平滑扩缩容、弹性扩展、透明读写分离，具备数据库全生命周期运维管控能力。DRDS 前身为淘宝 TDDL，是近千核心应用首选组件

# 索引
## 1 联合索引
比如a,b,c三个字段组成的联合索引,根据mysql最左匹配优先原则,在实际中其实是分成了a,ab,abc三个索引
```
select * from test where a=? and b=? and c=?；查询效率最高，索引全覆盖。
select * from test where a=? and b=?；索引覆盖a和b。
select * from test where b=? and a=?；经过mysql的查询分析器的优化，索引覆盖a和b。
select * from test where a=?；索引覆盖a。
select * from test where b=? and c=?；没有a列，不走索引，索引失效。
select * from test where c=?；没有a列，不走索引，索引失效。
```

## 2 聚簇索引
聚簇索引不是一种索引类型,而是一种存储数据的方式.Innodb的聚簇索引是在同一个数据结构中保存了索引和数据  
Innodb使用主键来进行聚簇索引,没有主键的话就会选择一个唯一的非空索引,如果还还没有,innodb会选择生成一个隐式的主键来进行聚簇索引  
这也是innodb推荐使用自增主键的原因,自增且连续,如果主键是无序的,那每操作一次,都会移动很多tree节点,代码无疑非常高  
其他索引的叶子节点存储的是主键,找到主键后,根据主键再进行一次索引,拿到数据

## 3 覆盖索引
innodb的索引设计模式是聚簇索引,所以我们有时候查找一些数据可以直接在索引层面就能找到,而不用回表,这样极大的减少从磁盘加载数据的数量,大大提高了sql的性能

## 4 索引下推
索引条件下推优化（Index Condition Pushdown (ICP) ）是MySQL5.6添加的，用于优化数据查询  
+ 不使用索引条件下推优化时存储引擎通过索引检索到数据，然后返回给MySQL服务器，服务器然后判断数据是否符合条件
+ 当使用索引条件下推优化时，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器。  
索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数,icp功能默认开启,可以通过系统变量optimizer_switch 控制开启关闭  
个人理解:也就是最大程度利用索引中的数据做判断,减少回表的次数,提升效率

## 5 MMR
MRR全称是Multi-Range Read，是MYSQL5.6优化器的一个新特性，在MariaDB5.5也有这个特性。优化的功能在使用二级索引做范围扫描的过程中减少磁盘随机IO和减少主键索引的访问次数。将随机IO转换为顺序IO  
在没有MRR的情况下，它是这样得到结果的：  
+ select key_column, pk_column from tb where key_column=x order by key_column ---> 假设这个结果集是t
+ for each row in t ; select non_key_column from tb where pk_column = pk_column_value。(在oracle里第2步叫回表)  

在有MRR的情况下，它是这样执行的：  
+ select key_column, pk_column from tb where key_column = x order by key_column ---> 假设这个结果集是t
+ 将结果集t放在buffer里面(直到buffer满了)，然后对结果集t按照pk_column排序 ---> 假设排序好的结果集是t_sort
+ select non_key_column fromtb where pk_column in (select pk_column from t_sort)  

总结:由于innodb是聚餐索引的结构,从索引指向的是主键id,这时候寻找到的主键id一般是无序的,会造成自盘随机读,只要开启的mmr,可以把结果放到一个buff里面,然后再去统一查找  


# 事务和锁
## 1 事务的特点
acid四个特性,a(原子性),c(一致性),i(隔离性),d(持久性)

## 2 隔离级别
+ 未提交读,也就是脏读
+ 提交读,只能看见已提交的事务做了修改,但是有时候会出现一个事务中前后两次读取同一个不一致,所以提交读又叫不可重复读
+ 可重复读 ,mysql的默认隔离级别,保证在一个事务中多次读取同样的记录都是一致的,但是会存在幻读问题,mysql是用mvcc解决这个问题的
+ 可串行化,强制事务串行执行
  
## 3 锁
+ 表锁 innodb和myisam都支持,行锁 innodb支持
+ 读写锁 写>读 可以多把读锁
+ 乐观锁,乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了,如果产生冲突再回滚.乐观锁避免了长事务中数据库的加锁开销
+ 悲观锁,悲观锁就是悲观主义者，它会认为我们在事务A中操作数据1的时候，一定会有事务B来修改数据1,所以，在第2步我们将数据查询出来后直接加上排它锁（X）锁，防止别的事务来修改事务1，直到我们commit后，才释放了排它锁。优点：保证了数据处理时的安全性。缺点：加锁造成了开销增加，并且增加了死锁的机会。降低了并发性。
+ 间隙锁 作用于非唯一索引上，主要目的，就是为了防止其他事务在间隔中插入数据，以导致“不可重复读”
+ 记录锁，它封锁索引记录，作用于唯一索引上
[参考链接](https://zhuanlan.zhihu.com/p/95207161)

## 4 mvcc
按照学习的锁的理论知识来说，如果我们update table set name='A' where id = 1;   
我们知道这肯定会给id=1这行数据添加了一个X锁，那么我们select * from table where id = 1；  
肯定是处于阻塞状态，但是为什么实际情况我们能够查询到数据呢?这就是MVCC厉害的地方了！  
在InnoDB中，给每行增加两个隐藏字段来实现MVCC，一个用来记录数据行的创建时间，另一个用来记录行的过期时间（删除时间）。  
在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。  
在RR级别下：SELECT读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。  
这样可以保证在读取之前记录是存在的。  
INSERT将当前事务的版本号保存至行的创建版本号  
UPDATE新插入一行，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号  
DELETE将当前事务的版本号保存至行的删除版本号
[参考链接](https://mp.weixin.qq.com/s/3Zk9Np5c9K0ENz64Y6E92g)

# 主从
## 1 主从的好处
+ 数据的备份
+ 突破单服务的qps瓶颈

## 2 主从原理
mysql的bin-log文件会记录所有的curd操作,主从实际就是把主库的bin-log复制过去,让从库在执行一次

## 3 主从数据不一致
主从时间跑一段时间后,有可能遇到两边数据不一致的情况 造成的原因很多,比如:网络,两台机器负载不一致,sql允许的最大执行占用内存不一致,也就是max_allowed_packet,自增id不一致等等  

怎么修复:1,数据很小,可以忽略的话,可以忽略错误,继续同步  2,重新重做主从,完全同步   3,使用第三方工具,比如pt

## 4 主从同步延时问题
+ 如果是主库写压力过大比如超过了2000qps,就可以把主库分成多个主库,减小主库压力
+ 打开mysql的并行复制,从库是单线程重放replaylog实现主从,思路打开多线程重放replaylog,缩短同步时间,[参考链接](https://www.w3cschool.cn/architectroad/architectroad-mysql-parallel-copy.html)
+ 特定的业务场景下直接读取主库